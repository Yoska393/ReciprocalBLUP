---
title: "b8_percent"
author: "Hayato Yoshioka"
date: "2025-10-20"
output: html_document
---

```{r}
require(BGLR)
require(here)
require(ggplot2)
require(reshape2)
require(gridExtra)
library(readr)
library(stringr)
library(ggsci)
library(RAINBOWR)
```


seed
```{r, message =F, include=FALSE}

# save or read the seed
seedIndCsv <-  here("out","seedInd.csv")
if (file.exists(seedIndCsv)) {
  seedInd <- read.csv(seedIndCsv, row.names = 1, header = T)
  seedInd <- c(as.matrix(seedInd))
} else {
  seedInd <- sample(1:500, 10, replace = F)
  write.csv(x = seedInd, file =  here("out","seedInd.csv"))
}

```




```{r}
## =========================================================

## Setup (keep the CD loop as is)

## =========================================================

for (CD in c("W1", "W4")) {

if (CD == "W4") {
file_name <- "blup_drought.rds"
} else if (CD == "W1") {
file_name <- "blup_control.rds"
} else {
stop("CD must be W1 or W4")
}

blup_data <- readRDS(here::here("data/blup", file_name))

pheno.sel.cd <- blup_data$pheno.sel.cd
var.id       <- blup_data$var.id
grm.cd       <- blup_data$grm.cd
plot.id      <- blup_data$plot.id
com.cd       <- blup_data$com.cd
met2.cd      <- blup_data$met2.cd
com2.cd      <- blup_data$com2.cd

# Set thresholds

f_list  <- readRDS(here("data","percentile_met_sets_G_COM_BOTH.rds"))
models  <- names(f_list)               # c("G_MET","COM_MET","BOTH")
percent <- c("100","50","25","12_5","6_25")
thresholds <- paste0(percent)          # Keep the same names for later use with intersect
n_repeat <- 10
if (!exists("seedInd")) seedInd <- 1:5

## ---------------------------------------------------------

## Utilities

## ---------------------------------------------------------

make_random_subsets_with_cov <- function(met_mat, num_met, nrep = 10, seed = NULL) {
if (!is.null(seed)) set.seed(seed)
# Assume num_met is a named integer vector (p100, p50, ...)
if (is.list(num_met)) {
nm_names <- names(num_met)
counts   <- sapply(num_met, function(x) as.integer(x[1]))
names(counts) <- nm_names
} else {
counts <- num_met
}
p <- ncol(met_mat)
out <- setNames(vector("list", length(counts)), names(counts))


for (per in names(counts)) {
  k_eff <- min(p, counts[[per]])
  rep_list <- vector("list", nrep)
  for (i in seq_len(nrep)) {
    cols <- sample(colnames(met_mat), size = k_eff, replace = FALSE)
    submat <- met_mat[, cols, drop = FALSE]
    X <- scale(submat, center = TRUE, scale = TRUE)
    covmat <- tcrossprod(X) / ncol(X)
    rep_list[[i]] <- list(cols = cols, submat = submat, cov = covmat)
  }
  out[[per]] <- rep_list
}
out


}

run_rainbow_cv <- function(Kmat, y_mat, seedInd) {
common_ids <- intersect(rownames(Kmat), rownames(y_mat))
stopifnot(length(common_ids) >= 5)
K <- Kmat[common_ids, common_ids, drop = FALSE]
y <- y_mat[common_ids, , drop = FALSE]


# Stabilize K
if (!is.matrix(K)) K <- as.matrix(K)
storage.mode(K) <- "double"
if (any(!is.finite(K))) {
  bad <- unique(which(!is.finite(K), arr.ind = TRUE)[,1])
  keep <- setdiff(seq_len(nrow(K)), bad)
  K <- K[keep, keep, drop = FALSE]
  y <- y[rownames(K), , drop = FALSE]
}
K <- (K + t(K)) / 2
ev <- suppressWarnings(eigen(K, symmetric = TRUE, only.values = TRUE)$values)
if (min(ev, na.rm = TRUE) < 0) {
  K <- as.matrix(Matrix::nearPD(K, keepDiag = TRUE)$mat)
}

# Convert y to numeric
y <- as.data.frame(y)
if (ncol(y) < 2) stop("y must have ID + >=1 trait columns")
for (j in 2:ncol(y)) y[[j]] <- suppressWarnings(as.numeric(y[[j]]))
ok_trait <- vapply(2:ncol(y), function(i) sum(is.finite(y[[i]])) >= 5, logical(1))
if (!all(ok_trait)) {
  y <- y[, c(TRUE, ok_trait), drop = FALSE]
  if (ncol(y) < 2) stop("All traits removed due to too many NAs")
}

amatZ <- RAINBOWR::design.Z(pheno.labels = rownames(y), geno.names = rownames(K))
ZETA  <- list(list(Z = amatZ, K = K))
X0    <- NULL

rep5 <- rep(1:5, length.out = nrow(y))
cor_by_seed <- vector("list", ncol(y) - 1)
names(cor_by_seed) <- colnames(y)[2:ncol(y)]

for (i in 2:ncol(y)) {
  y_full <- y[[i]]
  cor_vec <- rep(NA_real_, length(seedInd)); names(cor_vec) <- seedInd
  for (s in seq_along(seedInd)) {
    set.seed(seedInd[s])
    crossCvInd <- sample(rep5, nrow(y), replace = FALSE)
    pred <- rep(NA_real_, nrow(y))
    for (fold in 1:5) {
      testInd <- (crossCvInd == fold)
      yNa <- y_full; yNa[testInd] <- NA
      if (all(is.na(yNa))) next
      resEM3 <- RAINBOWR::EM3.cpp(y = yNa, X0 = X0, n.core = 1, ZETA = ZETA)
      pred[testInd] <- resEM3$y.pred[testInd]
    }
    if (!all(is.na(pred))) {
      cor_vec[s] <- suppressWarnings(cor(y_full, pred, use = "pairwise.complete.obs"))
    }
  }
  cor_by_seed[[colnames(y)[i]]] <- cor_vec
}

do.call(rbind, lapply(names(cor_by_seed), function(tr) {
  x <- cor_by_seed[[tr]]
  data.frame(trait = tr,
             cor_mean = mean(x, na.rm = TRUE),
             cor_var  = stats::var(x,  na.rm = TRUE),
             row.names = NULL)
}))


}

summarize_over_repeats <- function(summary_list) {
lapply(summary_list, function(rep_list) {
df <- do.call(rbind, lapply(seq_along(rep_list), function(r) {
cbind(rep = r, rep_list[[r]])
}))
agg <- do.call(rbind, lapply(split(df, df$trait), function(dd) {
data.frame(
trait         = unique(dd$trait),
cor_mean_mean = mean(dd$cor_mean, na.rm = TRUE),
cor_mean_var  = var(dd$cor_mean,  na.rm = TRUE),
cor_var_mean  = mean(dd$cor_var,  na.rm = TRUE),
n_rep         = nrow(dd)
)
}))
rownames(agg) <- NULL
agg
})
}

## =========================================================

## 1) Build “fixed K” for each model (create random only once after this)

## =========================================================

fixed_covs <- setNames(vector("list", length(models)), models)  # fixed_covs[[model]][[per]] = K
fixed_counts <- setNames(vector("list", length(models)), models) # Number of columns per threshold (remembered for random baseline)

for (model in models) {
met2_sub_list <- list()


for (per in percent) {
  thr_name <- paste0("p", per)
  if (per == "100") {
    met2.cd.sub <- met2.cd
  } else {
    selected_features <- if (CD == "W4") {
      f_list[[model]][[thr_name]]$drought
    } else {
      f_list[[model]][[thr_name]]$control
    }
    cols_to_keep <- intersect(colnames(met2.cd), selected_features)
    met2.cd.sub  <- met2.cd[, cols_to_keep, drop = FALSE]
  }
  met2_sub_list[[per]] <- met2.cd.sub
}

# Convert to covariance
cov_list <- lapply(met2_sub_list, function(submat) {
  if (is.null(submat) || ncol(submat) == 0) return(NULL)
  X <- scale(submat, center = TRUE, scale = TRUE)
  tcrossprod(X) / ncol(X)
})
fixed_covs[[model]] <- cov_list
fixed_counts[[model]] <- lapply(met2_sub_list, ncol)


}

## =========================================================

## 2) Create random K only once

## Match the number of columns per threshold to the reference model (default: BOTH)

## =========================================================

random_ref_model <- if ("BOTH" %in% models) "BOTH" else models[[1]]
num_met_for_random <- fixed_counts[[random_ref_model]]
names(num_met_for_random) <- names(fixed_covs[[random_ref_model]])  # "100","50",...

rand_met2_list <- make_random_subsets_with_cov(
met_mat = met2.cd,
num_met = num_met_for_random,
nrep    = n_repeat,
seed    = 123
)

# For convenience, keep only the cov in the same structure

rand_covs <- lapply(rand_met2_list, function(rep_list) {
lapply(rep_list, function(x) x$cov)
})

# rand_covs[[per]][[rep]] = K_rand

## =========================================================

## 3) Evaluate 4 candidates (3 fixed + RANDOM) × thresholds × repeats

## =========================================================

candidates <- c(models, "RANDOM")

# Containers for results: cor_summary[[candidate]][[per]][[rep_idx]] = data.frame(...)

cor_summary <- setNames(vector("list", length(candidates)), candidates)
for (cand in candidates) {
cor_summary[[cand]] <- setNames(vector("list", length(percent)), percent)
for (per in percent) {
cor_summary[[cand]][[per]] <- vector("list", n_repeat)
}
}

for (rep_idx in 1:n_repeat) {
message("==== Repeat: ", rep_idx, " / ", n_repeat, " ====")


for (per in percent) {

  # Prepare K for each candidate
  K_list <- list(
    G_MET   = fixed_covs[["G_MET"]][[per]],
    COM_MET = fixed_covs[["COM_MET"]][[per]],
    BOTH    = fixed_covs[["BOTH"]][[per]],
    RANDOM  = rand_covs[[per]][[rep_idx]]
  )

  for (cand in candidates) {
    Kmat <- K_list[[cand]]

    if (is.null(Kmat)) {
      warning("K is NULL at candidate=", cand, ", per=", per, ", rep=", rep_idx, ". Skip.")
      next
    }

    # Shared samples
    common_ids <- intersect(rownames(pheno.sel.cd), rownames(Kmat))
    if (length(common_ids) < 5) {
      warning("Too few common samples at candidate=", cand, ", per=", per, ", rep=", rep_idx, ". Skip.")
      next
    }

    y_sub <- pheno.sel.cd[common_ids, , drop = FALSE]
    K_al  <- as.matrix(Kmat[common_ids, common_ids, drop = FALSE]); storage.mode(K_al) <- "double"

    res <- run_rainbow_cv(K_al, y_sub, seedInd)
    cor_summary[[cand]][[per]][[rep_idx]] <- res
  }
}

}

## =========================================================

## 4) Summarize 10 repeats per threshold (for each candidate)

## =========================================================

cor_summary10 <- lapply(cor_summary, summarize_over_repeats)

## =========================================================

## 5) Save

## - per_repeat: raw results for candidate → threshold → repeat

## - summary10 : aggregated per threshold for each candidate (e.g., cor_mean_mean)

## =========================================================

saveRDS(
list(
per_repeat = cor_summary,   # list[candidate][[per]][[rep]] -> data.frame
summary10  = cor_summary10  # list[candidate][[per]]        -> data.frame
),
here::here("out", paste0("rainbow_cor_summary_", CD, "_4cands.rds"))
)
}

```



read
```{r, message =F,include=FALSE}
cor_all<-readRDS(here::here("out", paste0("rainbow_cor_summary_", CD, "_4cands.rds")))

cor_all$summary10
```

ONLY ONCE
```{}
## =========================

## CV with standard GBLUP (grm.cd)

## =========================

# 1) Align sample IDs

rownames(grm.cd)<-rownames(pheno.sel.cd)
colnames(grm.cd)<-rownames(pheno.sel.cd)
common_ids <- intersect(rownames(grm.cd), rownames(pheno.sel.cd))
stopifnot(length(common_ids) >= 5)

K_g <- grm.cd[common_ids, common_ids, drop = FALSE]
y_g <- pheno.sel.cd[common_ids, , drop = FALSE]

# 2) Make K safe (symmetrize and ensure positive semidefiniteness)

K_g <- as.matrix(K_g); storage.mode(K_g) <- "double"
K_g <- (K_g + t(K_g)) / 2
ev  <- suppressWarnings(eigen(K_g, symmetric = TRUE, only.values = TRUE)$values)
if (min(ev, na.rm = TRUE) < 0) {
K_g <- as.matrix(Matrix::nearPD(K_g, keepDiag = TRUE)$mat)
}

# 3) Use existing run_rainbow_cv() as is

# (seedInd is already prepared in your code)

res_gblup <- run_rainbow_cv(Kmat = K_g, y_mat = y_g, seedInd = seedInd)

# 4) Save

dir.create(here::here("out", "gblup_cv", CD), recursive = TRUE, showWarnings = FALSE)
saveRDS(res_gblup, here::here("out", paste0("gblup_cv_", CD, ".rds")))

# write.csv(res_gblup, here::here("out", "gblup_cv", CD, paste0("gblup_", CD, ".csv")),

# row.names = FALSE)

# 5) (Optional) Merge into an existing results object to plot/compare later together

# Example: name it for side-by-side comparison with fixed K (thresholds)

gblup_summary <- res_gblup # columns: trait, cor_mean, cor_var


```

